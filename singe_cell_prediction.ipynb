{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93bb1385-1d47-4a28-bdc6-b8318e4f2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(pow(2,40))\n",
    "import pickle\n",
    "from glob import glob\n",
    "from typing import Tuple\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "#from patchify import patchify, unpatchify\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import openslide\n",
    "import pandas as pd\n",
    "#from models.HoVerNet.post_proc import process\n",
    "\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tensorboardX import SummaryWriter\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "import json\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "import openslide\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b08edd-53c2-4a6a-a193-fa9e14395f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wsi_path = '../GTEX-1117F-0226.svs'\n",
    "nuc_map_path = '../nulci.png'\n",
    "\n",
    "infer_omic = 'humanrna'\n",
    "assert infer_omic in ['snp', 'ms', 'mirna', 'cnv', 'humanrna', 'methyl']\n",
    "\n",
    "\n",
    "save_matrix_path = f'../{infer_omic}_scpred.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0abf20a-ef06-48df-b5f2-b90ce9b357ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "gene_names = torch.load(f'{infer_omic}_names.pth')\n",
    "\n",
    "model = timm.create_model('efficientnet_b3.ra2_in1k', pretrained=False)\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3, inplace=True),\n",
    "    nn.Linear(in_features=1536, out_features=len(gene_names), bias=True),\n",
    ")\n",
    "\n",
    "model.load_state_dict({k.replace('_orig_mod.', ''): v for k, v in torch.load(f'../model_weights/{infer_omic}_model.pth').items()})#, strict=False)\n",
    "\n",
    "model = model.to('cuda')\n",
    "model.eval()\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3884aa03-d8c6-4971-8b31-358e033ece4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class OpenSlideInferenceDataset(Dataset):\n",
    "    def __init__(self, yx_array, transform=None):\n",
    "\n",
    "        self.yx_array = yx_array\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        center_y, center_x = self.yx_array[idx]\n",
    "        #print(center_y, center_x)\n",
    "        #print(center_y-256, center_y+256, center_x-256, center_x+256)\n",
    "        img = im_20x[center_y-256:center_y+256, center_x-256:center_x+256]\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented['image']\n",
    "\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.yx_array.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a813429-9146-4ed5-8c92-665ed868613b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = A.Compose([\n",
    "    #A.CenterCrop(224, 224),\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    #A.Normalize(mean=[0.7343752, 0.734179, 0.7339175], std=[0.1848752, 0.18325073, 0.18443637]),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b59bd32-acb6-4b30-acd2-8fe87cadb7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ba85274bc847bcaf483a515ee68008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_path = input_wsi_path\n",
    "slide = openslide.OpenSlide(input_path)\n",
    "level = slide.properties.get('openslide.objective-power')\n",
    "\n",
    "width, height = slide.level_dimensions[0]\n",
    "im_20x = slide.read_region((0, 0), 0, (width, height))\n",
    "im_20x = np.array(im_20x)[:, :, :3]\n",
    "\n",
    "if level == '40':\n",
    "    im_20x = cv2.resize(im_20x, (im_20x.shape[1]//2, im_20x.shape[0]//2))\n",
    "elif level == '20':\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('Only WSIs with magnifications of 20 and 40x are supported currently.')\n",
    "\n",
    "h, w, c = im_20x.shape\n",
    "\n",
    "binary_mask = cv2.imread(nuc_map_path, cv2.IMREAD_UNCHANGED)\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Loop through the contours to find bounding box centers\n",
    "all_yxs = []\n",
    "\n",
    "for contour in contours:\n",
    "    # Calculate bounding box\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "    # Calculate the center of the bounding box\n",
    "    cX = x + w // 2\n",
    "    cY = y + h // 2\n",
    "\n",
    "    all_yxs.append([cY, cX])\n",
    "\n",
    "yx_array = np.array(all_yxs)\n",
    "yx_array[:, 0] = yx_array[:, 0].clip(256, im_20x.shape[0]-256)\n",
    "yx_array[:, 1] = yx_array[:, 1].clip(256, im_20x.shape[1]-256)\n",
    "\n",
    "val_dataset = OpenSlideInferenceDataset(yx_array, transform=transform_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1024, shuffle=False, num_workers=16, pin_memory=True, drop_last=False)\n",
    "\n",
    "all_pres = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(val_loader):\n",
    "        images = images.to('cuda')\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "\n",
    "        all_pres.append(outputs.sigmoid().cpu().numpy())\n",
    "\n",
    "all_pres = np.concatenate(all_pres, axis=0)\n",
    "all_pres_df = pd.DataFrame(all_pres)\n",
    "all_pres_df.columns = gene_names\n",
    "y_x_index_df = pd.DataFrame({\n",
    "        \n",
    "                        'x_center': yx_array[:, 1],\n",
    "                        'y_center': yx_array[:, 0],\n",
    "                         \n",
    "                        })\n",
    "final_df = pd.concat([y_x_index_df, all_pres_df], axis=1)\n",
    "final_df.T.to_csv(save_matrix_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3627c-db1e-4b8f-b616-3ea87f36184a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
