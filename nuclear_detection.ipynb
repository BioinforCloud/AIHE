{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86a174d2-cd6c-4e44-bcd5-4e3ab40e9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('../HoVer-UNet/')\n",
    "import os\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = str(pow(2,40))\n",
    "import pickle\n",
    "from glob import glob\n",
    "from typing import Tuple\n",
    "from skimage.io import imread\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "#from patchify import patchify, unpatchify\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import openslide\n",
    "import pandas as pd\n",
    "from models.HoVerNet.post_proc import process\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tensorboardX import SummaryWriter\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "import json\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import openslide\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5d718-372f-4df6-ac04-3e201cb19bd9",
   "metadata": {},
   "source": [
    "### Replace with your own WSI filepath and save dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aca8cf2-a452-43a5-854a-e6a44a81da12",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_wsi_path = '../GTEX-1117F-0226.svs'\n",
    "save_nuc_map_path = '../nulci.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d13522e-395b-4a10-a0fe-13549b1ced3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'CC': 'CC',\n",
    "    'EmAC': 'EC',\n",
    "    'MC': 'MC',\n",
    "    'PSPC': 'SC',\n",
    "    'PsC': 'SC',\n",
    "    'PSC': 'SC',\n",
    "    'Psc': 'SC',\n",
    "    'PSPC': 'SC',\n",
    "    'UC': 'Other'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c1c090-4c8b-439a-8961-c921679dbc7c",
   "metadata": {},
   "source": [
    "### Download hover_unet_weights.pth and place it in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0319e16-2664-4d6a-8f19-defed82c2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasthovernet = smp.Unet(encoder_name='mit_b2', classes=10, in_channels=3, encoder_weights=None).cuda()\n",
    "fasthovernet.load_state_dict(torch.load('../model_weights/hover_unet_weights.pth')['model_state_dict'])\n",
    "_ = fasthovernet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ed26b4-fd38-4ab8-97b9-8baff999313b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8bd0c49a9f48bf919e7e8a02421924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slide = openslide.OpenSlide(input_wsi_path)\n",
    "level = slide.properties.get('openslide.objective-power')\n",
    "\n",
    "width, height = slide.level_dimensions[0]\n",
    "im_20x = slide.read_region((0, 0), 0, (width, height))\n",
    "im_20x = np.array(im_20x)[:, :, :3]\n",
    "\n",
    "if level == '40':\n",
    "    im_20x = cv2.resize(im_20x, (im_20x.shape[1]//2, im_20x.shape[0]//2))\n",
    "elif level == '20':\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('Only WSIs with magnifications of 20 and 40x are supported currently.')\n",
    "    \n",
    "h, w, c = im_20x.shape\n",
    "\n",
    "patch_size = 512\n",
    "stride = 256\n",
    "\n",
    "full_pred_map = torch.zeros((10, h, w), dtype=torch.float16)\n",
    "full_overlap_map = torch.zeros((h, w), dtype=torch.int8)\n",
    "\n",
    "for x_start in tqdm(range(0, w-patch_size, stride)):\n",
    "    for y_start in range(0, h-patch_size, stride):\n",
    "\n",
    "        ipt = torch.tensor(im_20x[y_start:y_start+patch_size, x_start:x_start+patch_size]).unsqueeze(0).permute(0, 3, 1, 2) / 255\n",
    "        with torch.no_grad():\n",
    "            preds = fasthovernet(ipt.cuda())\n",
    "\n",
    "        full_pred_map[:, y_start:y_start+patch_size, x_start:x_start+patch_size] += preds[0].cpu()\n",
    "        full_overlap_map[y_start:y_start+patch_size, x_start:x_start+patch_size] += 1\n",
    "\n",
    "del im_20x\n",
    "gc.collect()\n",
    "\n",
    "preds = full_pred_map / full_overlap_map\n",
    "\n",
    "preds = preds.permute(1, 2, 0).unsqueeze(0).float()\n",
    "\n",
    "del full_pred_map, full_overlap_map\n",
    "gc.collect()\n",
    "\n",
    "pred_np = F.softmax(preds[..., :2], dim=-1)[..., 1][..., None]\n",
    "pred_hv = preds[..., 2:4]\n",
    "pred_tp = torch.argmax(F.softmax(preds[..., 4:], dim=-1), dim=-1)[..., None]\n",
    "preds = torch.cat([pred_tp, pred_np, pred_hv], dim=-1)\n",
    "\n",
    "mask = preds[:, :, :, 0].cpu().numpy()#.astype(np.uint8)\n",
    "binary_mask = (mask[0] > 0).astype(np.uint8)*255\n",
    "\n",
    "del mask, preds, pred_tp, pred_hv, pred_np\n",
    "gc.collect()\n",
    "\n",
    "cv2.imwrite(save_nuc_map_path, binary_mask)\n",
    "\n",
    "del binary_mask\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
